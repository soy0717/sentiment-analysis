{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    #remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "    lem = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lem.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "def sentiment_analysis(text):\n",
    "\n",
    "    scores = analyser.polarity_scores(text)\n",
    "    sentiment = 'positive' if scores['compound'] > 0 else 'negative' if scores['compound'] < 0 else 'neutral'\n",
    "    return sentiment, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6938837b014dd990d60fadbc6b7109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Soy\\Sentiment Analysis Project\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sai Sreya\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e1adf8883949d28eedd45f927ccae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71ef212e0824adf9f9720a87682a702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e42abb6e6994f689658056827e2ee6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1c3c68302a461da05bdaf157902503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76208bc6f0e242f6a16748806084ee87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6896d10672a445a98efdfee770e3146b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"gpt2\"  # Replace with \"EleutherAI/gpt-neo-125M\" for GPT-Neo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot function\n",
    "def chatbot(user_input):\n",
    "    cleaned_input = preprocess(user_input)\n",
    "\n",
    "    # Perform sentiment analysis\n",
    "    sentiment, scores = sentiment_analysis(cleaned_input)\n",
    "\n",
    "    if sentiment == 'positive':\n",
    "        prompt = f\"The user is feeling good. How can I respond positively to: {user_input}?\"\n",
    "    elif sentiment == 'negative':\n",
    "        prompt = f\"The user seems to be feeling down. How can I respond supportively to: {user_input}?\"\n",
    "    else:\n",
    "        prompt = f\"The user seems neutral. How should I respond to: {user_input}?\"\n",
    "\n",
    "    # Generate the response\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"sentiment_scores\": scores,\n",
    "        \"gpt2_response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good. How can I respond positively to: I'm feeling down today? I'm feeling good.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_query = \"I'm feeling down today\"\n",
    "result = chatbot(user_query)\n",
    "print(result['gpt2_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
